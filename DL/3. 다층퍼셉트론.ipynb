{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3c8f30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bbc8dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93471891",
   "metadata": {},
   "source": [
    "# 데이터 전처리\n",
    "\n",
    "- 픽셀값을 0 ~ 1 사이로 스케일링\n",
    "- 2차원 배열을 1차원 배열로 변환\n",
    "- 훈련, 검증 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c52d98e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = x_train / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a943dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train = scaled_train.reshape(-1, 28 * 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca6311bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_train, scaled_val, y_train, y_val = train_test_split(scaled_train, y_train,\n",
    "                                                           test_size = 0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1c9b4",
   "metadata": {},
   "source": [
    "# 심층 신경망 구성\n",
    "\n",
    "- 인공 신경망에 층을 추가한 구조\n",
    "<img src = \"./image/ml_perceptron.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f52e57",
   "metadata": {},
   "source": [
    "- 단층 퍼셉트론과의 차이는 입력층과 출력층 사이에 밀집층이 추가되는 것\n",
    "    - 입력층과 출력층 사이에 있는 모든 층을 은닉층(hidden layer)라고 부름\n",
    "    \n",
    "- 출력층에 적용하는 활성화 함수와 은닉층에 적용하는 활성화 함수는 차이가 있음\n",
    "    - 출력층의 활성화 함수\n",
    "        - 출력층 함수라고도 부름\n",
    "        - 결과물을 적절한 형식으로 출력하도록 유도해서 데이터셋과 잘 비교할 수 있도록 하는 역할\n",
    "        - 종류에 제한이 있음(이진 분류 : 시그모이드, 다중 분류 : 소프트맥스)\n",
    "        \n",
    "    - 은닉층의 활성화 함수\n",
    "        - 여러 겹의 layer들 사이에서 사용됨\n",
    "        - 출력층에 비해 선택이 자유로움\n",
    "        - 대표적인 활성화 함수 : ReLU(렐루)\n",
    "        - 모든 신경망의 은닉층에는 항상 활성화 함수가 있음\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55446218",
   "metadata": {},
   "source": [
    "<img src = \"./image/activation.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3df6e",
   "metadata": {},
   "source": [
    "- 활성화 함수(activation function)\n",
    "    - 활성화 함수를 쓰는 이유\n",
    "        - 예) a * 4 + 2 = b\n",
    "        - b * 3 - 5 = c\n",
    "        - 위 2개의 식은 a * 12 + 1 = c 로 단순화가 가능\n",
    "        \n",
    "    - 은닉층이 선형적인 산술계산만 한다면 층이 깊어지더라도 계산식이 단순화되어 학습 효율이 떨어짐\n",
    "        - 따라서 활성화함수로 선형계산을 비선형 계산으로 비틀어주는 과정이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4261624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 은닉층\n",
    "dense1 = keras.layers.Dense(100, activation = \"sigmoid\", input_shape = (784,))\n",
    "\n",
    "# 출력층\n",
    "dense2 = keras.layers.Dense(10, activation = \"softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a7a336",
   "metadata": {},
   "source": [
    "- dense1\n",
    "    - 은닉층\n",
    "        - 유닛 개수를 정하는 것은 특별한 기준이 없음\n",
    "        - 다만 출력층의 유닛보다는 많은 것을 추천\n",
    "            - 은닉층의 유닛이 출력층보다 적다면 전달되는 정보량이 부족해질 수 있음 \n",
    "    - 활성화 함수는 시그모이드 \n",
    "    - 입력층과 연결되기 때문에 입력의 크기는 (784,)\n",
    "    \n",
    "- dense2\n",
    "    - 10개의 클래스로 분류하며 10개의 유닛\n",
    "    - 다중 분류이기 때문에 활성화 함수는 소프트맥스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5e52f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f68f51",
   "metadata": {},
   "source": [
    "**가장 처음 등장하는 은닉층부터 마지막 출력층까지 순서대로 추가해야함**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4e95983",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(dense1)\n",
    "model.add(dense2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c732201a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce700b8",
   "metadata": {},
   "source": [
    "- 모델 요약 정보\n",
    "    - 모델에 포함된 층들이 순서대로 나열됨\n",
    "        - 첫 은닉층부터 출력층까지\n",
    "    - 층마다 이름, 클래스, 출력 크기, 파라미터 개수가 나옴\n",
    "        - 이름\n",
    "            - 층을 만들 때 name 매개변수로 지정 가능\n",
    "            - 지정하지 않으면 기본값 \"dense\"\n",
    "            \n",
    "    - Output Shape\n",
    "        - 출력 크기\n",
    "        - (None, 100)\n",
    "            - 첫 번째 차원은 샘플의 개수를 의미\n",
    "            - 샘플의 개수가 None인 이유는 한 번에 몇 개의 이미지씩 사용할 지 알 수 없기 때문에 어떤 배치크기에도 유연하게 대응할 수 있도록 None 으로 설정\n",
    "                - 케라스는 기본적으로 미니배치 경사하강법을 사용\n",
    "                - batch_size 를 설정하지 않으면 기본값 32\n",
    "                - 따라서 input_shape 나 output_shape 의 첫 번째 차원을 배치 차원이라고 부름\n",
    "            - 두 번째 차원은 출력 개수\n",
    "                - 100개의 유닛에서 결과가 나오기 때문에 출력 개수가 100\n",
    "                - 즉, 각 이미지마다 784개의 픽셀값이 은닉층을 통과하면서 100개의 특성으로 압축됨\n",
    "        \n",
    "    - Param\n",
    "        - 모델 파라미터 개수\n",
    "        - 은닉층\n",
    "            - 784 픽셀의 입력값과 100개의 유닛의 모든 조합에 대한 가중치 + 각 유닛의 절편 1개씩\n",
    "                - 784 * 100 + 100 = 78500\n",
    "                \n",
    "        - 출력층\n",
    "            - 앞 은닉층의 100개의 유닛과 10개의 출력층 유닛의 모든 조합에 대한 가중치 + 각 유닛의 절편 1개씩\n",
    "                - 100 * 10 + 10 = 1010\n",
    "                \n",
    "    - Non-trainable params\n",
    "        - 훈련되지 않은 파라미터\n",
    "        - 경사하강법으로 훈련되지 않ㅇ느 파라미터를 가진 층이 있다면 여기에 표시됨\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f70daa",
   "metadata": {},
   "source": [
    "## 층을 추가하는 다른 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "179289e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation = \"sigmoid\", input_shape = (784,), name = \"hidden\"),\n",
    "    keras.layers.Dense(10, activation = \"softmax\", name = \"output\") \n",
    "], name = \"Fashion_MNIST_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ed5a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Fashion_MNIST_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden (Dense)              (None, 100)               78500     \n",
      "                                                                 \n",
      " output (Dense)              (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55430279",
   "metadata": {},
   "source": [
    "- 여러 모델과 많은 층을 사용할 때 구분을 위해서 name 매개변수를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31aa47f",
   "metadata": {},
   "source": [
    "# 모델 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9a3b2646",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00a18787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5798 - accuracy: 0.8025\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.4133 - accuracy: 0.8514\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3771 - accuracy: 0.8637\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3540 - accuracy: 0.8710\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3380 - accuracy: 0.8762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f742bc3490>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8857f99",
   "metadata": {},
   "source": [
    "- 은닉층의 추가로 훈련 세트에 대한 성능이 향상됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d40f3",
   "metadata": {},
   "source": [
    "# 활성화 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e21aaa",
   "metadata": {},
   "source": [
    "## 시그모이드\n",
    "\n",
    "<img src = \"./image/sigmoid.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01685db9",
   "metadata": {},
   "source": [
    "- 초창기 인공 신경망의 은닉층에서 많이 사용된 활성화 함수는 시그모이드\n",
    "- 입력값이 아무리 크더라도 0 ~ 1 사이의 값으로 출력되어 출력값의 범위가 너무 좁음\n",
    "    - 경사하강법 수행 시에 기울기가 0에 수렴하는 기울기 소실(Gradient Vanshing)이 발생할 수 있음\n",
    "    - 층이 많아지고 모델이 복잡해질수록 그 효과가 누적되어 더욱 학습을 어렵게 만듦"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b6c3e8",
   "metadata": {},
   "source": [
    "## 렐루 함수(ReLU)\n",
    "\n",
    "<img src = \"./image/relu.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348b36a1",
   "metadata": {},
   "source": [
    "- 입력이 양수일 경우 마치 활성화 함수가 없는 것처럼 그냥 입력을 통과시키고, 음수일 경우에는 0이 됨\n",
    "- 표현식 : max(0, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae65702",
   "metadata": {},
   "source": [
    "# Flatten\n",
    "\n",
    "- 지금까지는 패션 MNIST 데이터가 28 * 28 크기이기 때문에 인공신경망에 주입하기 전에 reshape를 이용하여 1차원으로 펼쳤음\n",
    "    - 샘플의 개수가 차원을 제외하고 나머지 모든 입력 차원을 일렬로 펼쳐주는 역할\n",
    "    - 가중치나 절편이 없음\n",
    "    - 하지만 입력층과 은닉층 사이에 추가하기 때문에 편의상 층이라고 부르지만 신경망의 깊이가 깊어진 것으로 보지 않음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab851c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3320b4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ec1df",
   "metadata": {},
   "source": [
    "- Flatten 층의 파라미터는 0\n",
    "- Flatten 층을 추가하면 입력값의 차원을 짐작할 수 있다는 것이 장점\n",
    "    - 784개의 입력이 첫 번째 은닉층에 전달된다는 것이 명확하게 드러남\n",
    "- 입력 데이터에 대한 전처리 과정을 가능한한 모델에 포함시키는 것이 케라스 API의 철학 중 하나"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bccc11",
   "metadata": {},
   "source": [
    "# 새 모델을 위한 데이터를 다시 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0fe6b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "scaled_train = x_train / 255\n",
    "scaled_train, scaled_val, y_train, y_val = train_test_split(scaled_train, y_train,\n",
    "                                                           test_size = 0.2, random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bbba08c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48000, 28, 28)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b9aedf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5e95ac60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5406 - accuracy: 0.8096\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3985 - accuracy: 0.8564\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3567 - accuracy: 0.8705\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3352 - accuracy: 0.8780\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 2s 2ms/step - loss: 0.3209 - accuracy: 0.8848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f7430e3bd0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2ce3a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3665 - accuracy: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.36647993326187134, 0.8700000047683716]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073f7728",
   "metadata": {},
   "source": [
    "# 딥러닝의 하이퍼파라미터\n",
    "\n",
    "- 하이퍼파라미터 : 모델이 학습하지 않아 사람이 지정해 주어야하는 파라미터\n",
    "- 인공 신경망에서 하이퍼파라미터의 종류\n",
    "    - 은닉층의 개수\n",
    "    - 은닉층의 유닛 개수\n",
    "    - 활성화 함수\n",
    "    - 층의 종류\n",
    "        - 밀집층, CNN, RNN \n",
    "    - 미니배치 개수(batch_size)\n",
    "    - 반복 횟수(epochs)\n",
    "    - 옵티마이저(optimizer)\n",
    "    - 옵티마이저의 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8314b7de",
   "metadata": {},
   "source": [
    "## 옵티마이저\n",
    "\n",
    "- 케라스에서는 기본적으로 경사 하강법 알고리즘(RMSprop)을 사용\n",
    "- 이 외에도 다양한 경사 하강법 알고리즘을 제공하고, 이를 옵티마이저 라고 부름\n",
    "<img src = \"./image/optimizer.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba7d19e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd 옵티마이저를 사용하려면\n",
    "sgd = keras.optimizers.SGD()\n",
    "model.compile(optimizer = sgd, loss  = \"sparse_categorical_crossentropy\", metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1713cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위와 동일한 코드\n",
    "# 원래는 위의 코드처럼 각각의 클래스 객체를 만들어서 사용하는 것이 정석\n",
    "# 번거로움을 피하기 위해 \"sgd\" 라고 입력하면 자동으로 SGD 클래스 객체를 생성해줌\n",
    "model.compile(optimizer = \"sgd\", loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78e7a9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저의 학습률을 조절하고 싶다면\n",
    "sgd = keras.optimizers.SGD(learning_rate = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec675a9",
   "metadata": {},
   "source": [
    "### 옵티마이저의 종류\n",
    "\n",
    "- Momentum\n",
    "    - SGD 클래스에서 momentum 기본값은 0\n",
    "    - momentum을 0보다 큰 값으로 지정하면 모멘텀 최적화(momentum optimization)을 사용 \n",
    "    - 일반적으로 momentum 매개변수는 0.9 이상을 지정\n",
    "    \n",
    "- NAG(Nesterov Accelerated Gradient)\n",
    "    - SGD 클래스의 nesterov 매개변수를 기본값 False 에서 True 로 바꾸면 네스테로프 모멘텀 최적화를 사용할 수 있음\n",
    "    - 대부분의 경우 네스테로프 모멘텀 최적화가 기본 경사 하강법 보다는 더 나은 성능을 제공\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15d5e2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 네스테로프 모멘텀 최적화\n",
    "nag = keras.optimizers.SGD(momentum = 0.9, nesterov = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5905dd0d",
   "metadata": {},
   "source": [
    "- 적응적 학습률(adaptive learning rate)\n",
    "    - 모델이 최적점에 가까이 갈수록 학습률을 낮춤\n",
    "        - 안정적으로 최적점에 수렴할 가능성이 높음\n",
    "    - 적응적 학습률을 사용하는 대표적인 옵티마이저\n",
    "        - Adagrad, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "11816189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adagrad \n",
    "adagrad = keras.optimizers.Adagrad()\n",
    "model.compile(optimizer = adagrad, loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f4955e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSprop\n",
    "rmsprop = keras.optimizers.RMSprop()\n",
    "model.compile(optimizer = rmsprop, loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a2371e",
   "metadata": {},
   "source": [
    "- 위의 모멘텀 최적화와 적응적 학습률을 접목한 것이 Adam\n",
    "    - 기본적으로 가장 많이 쓰이는 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be16c204",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape = (28, 28)))\n",
    "model.add(keras.layers.Dense(100, activation = \"relu\"))\n",
    "model.add(keras.layers.Dense(10, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc5e64f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_2 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               78500     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 79510 (310.59 KB)\n",
      "Trainable params: 79510 (310.59 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fc583686",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\",\n",
    "             metrics = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "749b0d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.5339 - accuracy: 0.8138\n",
      "Epoch 2/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3972 - accuracy: 0.8583\n",
      "Epoch 3/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3556 - accuracy: 0.8721\n",
      "Epoch 4/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3315 - accuracy: 0.8781\n",
      "Epoch 5/5\n",
      "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3114 - accuracy: 0.8867\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1f74119bbd0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(scaled_train, y_train, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5ebc78df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 1s 1ms/step - loss: 0.3192 - accuracy: 0.8881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.319176584482193, 0.8880833387374878]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(scaled_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ad7c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
