{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a164142a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3df1416b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../ML/data/boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "25251e67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf53328",
   "metadata": {},
   "source": [
    "- 보스턴 집값 데이터 독립변수\n",
    "    - CRIM : 인구 1명당 범죄 발생 수\n",
    "    - ZN : 25,000 평방 피트 이상의 주거 구역 비중\n",
    "    - INDUS : 소매업 외 상업이 차지하는 면적 비율\n",
    "    - CHAS : 찰스강 위치 변수(1 : 강 주변, 0 : 이외)\n",
    "    - NOX : 일산화질소 농도\n",
    "    - RM : 집의 평균 방 수 \n",
    "    - AGE : 1940년 이전에 지어진 비율\n",
    "    - DIS : 5가지 보스턴 시 고용 시설까지의 거리\n",
    "    - RAD : 순환 고속도로의 접근 용이성\n",
    "    - TAX : $10,000 당 부동산 세율 총계\n",
    "    - PTRATIO : 지역별 학생과 교사 비율\n",
    "    - B : 지역별 흑인 비율\n",
    "    - LSTAT : 급여가 낮은 직업에 종사하는 인구 비율(%)\n",
    "    \n",
    "- 종속변수\n",
    "    - PRICE : 가격(단위 : $1,000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f77b7f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     506 non-null    float64\n",
      " 1   ZN       506 non-null    float64\n",
      " 2   INDUS    506 non-null    float64\n",
      " 3   CHAS     506 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      506 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    float64\n",
      " 9   TAX      506 non-null    float64\n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    506 non-null    float64\n",
      " 13  PRICE    506 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75f8b0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT       PRICE  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f0cb578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 14)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "588c8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 분할\n",
    "x = df.drop('PRICE', axis = 1)\n",
    "y = df[\"PRICE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b3cbd2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2,\n",
    "                                    random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05f6a3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sub, x_val, y_sub, y_val = train_test_split(x_train, y_train, test_size = 0.2,\n",
    "                                             random_state = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "62131f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323, 13)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_sub.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5169be9",
   "metadata": {},
   "source": [
    "# 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8afffe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac049d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층1\n",
    "model.add(keras.layers.Dense(30, activation = \"relu\", input_shape = (13,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c2530b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 은닉층2\n",
    "model.add(keras.layers.Dense(6, activation = \"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3b63019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력층\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a07e70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience = 16, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "957f88a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = \"adam\", loss = \"mean_squared_error\", \n",
    "              metrics = [\"mae\"])  # [\"mae\"] = mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2fc0339f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_3 (Dense)             (None, 30)                420       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 6)                 186       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 613 (2.39 KB)\n",
      "Trainable params: 613 (2.39 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ab540b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "11/11 [==============================] - 1s 18ms/step - loss: 4492.6045 - mae: 56.6294 - val_loss: 2431.6064 - val_mae: 27.2906\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2379.4968 - mae: 24.1520 - val_loss: 1973.9734 - val_mae: 22.9953\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1536.9489 - mae: 20.6642 - val_loss: 1177.5126 - val_mae: 22.0418\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 1108.9989 - mae: 22.9215 - val_loss: 884.7100 - val_mae: 20.4964\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 806.9932 - mae: 19.1476 - val_loss: 759.9204 - val_mae: 19.0855\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 667.2475 - mae: 17.6908 - val_loss: 631.8544 - val_mae: 18.3209\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 564.1830 - mae: 17.0734 - val_loss: 548.2155 - val_mae: 17.5464\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 495.1643 - mae: 16.1763 - val_loss: 497.9563 - val_mae: 16.8194\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 448.1926 - mae: 15.6640 - val_loss: 446.8943 - val_mae: 16.2539\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 413.2737 - mae: 14.9787 - val_loss: 418.9344 - val_mae: 15.6956\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 373.7431 - mae: 14.4751 - val_loss: 376.2588 - val_mae: 15.1426\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 341.9384 - mae: 13.8337 - val_loss: 356.7144 - val_mae: 14.6170\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 314.8654 - mae: 13.3067 - val_loss: 329.3646 - val_mae: 14.0855\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 294.5834 - mae: 12.7422 - val_loss: 312.4896 - val_mae: 13.6134\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 271.0076 - mae: 12.3337 - val_loss: 278.9591 - val_mae: 13.2195\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 262.7064 - mae: 12.5034 - val_loss: 273.9976 - val_mae: 12.8884\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 272.1840 - mae: 12.0309 - val_loss: 260.0253 - val_mae: 12.5297\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 222.3082 - mae: 11.3823 - val_loss: 235.9444 - val_mae: 12.2288\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 213.9811 - mae: 11.0939 - val_loss: 232.9728 - val_mae: 11.9688\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 205.7629 - mae: 11.0519 - val_loss: 217.8060 - val_mae: 11.8377\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 191.1012 - mae: 10.4943 - val_loss: 222.2780 - val_mae: 11.5686\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 187.3041 - mae: 10.2155 - val_loss: 195.2500 - val_mae: 11.2094\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 174.2225 - mae: 10.2986 - val_loss: 189.5841 - val_mae: 11.0407\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 167.1072 - mae: 10.0640 - val_loss: 191.0645 - val_mae: 10.8992\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 157.5349 - mae: 9.7023 - val_loss: 175.2472 - val_mae: 10.6135\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 152.8200 - mae: 9.6003 - val_loss: 172.4786 - val_mae: 10.2834\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 147.7088 - mae: 9.1348 - val_loss: 159.4471 - val_mae: 10.0809\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 142.0391 - mae: 9.2404 - val_loss: 159.3831 - val_mae: 9.8774\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 138.6105 - mae: 8.7788 - val_loss: 149.8572 - val_mae: 9.8210\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 137.6630 - mae: 9.2438 - val_loss: 154.5696 - val_mae: 9.6068\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 139.5554 - mae: 8.6516 - val_loss: 140.8022 - val_mae: 9.5086\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 127.7888 - mae: 8.8104 - val_loss: 150.5332 - val_mae: 9.2950\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 122.9620 - mae: 8.2234 - val_loss: 132.8805 - val_mae: 9.1002\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 118.9181 - mae: 8.2405 - val_loss: 134.5913 - val_mae: 8.9298\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 116.0216 - mae: 8.2654 - val_loss: 127.3989 - val_mae: 8.9038\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 111.9127 - mae: 8.0116 - val_loss: 127.1295 - val_mae: 8.6913\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 109.4192 - mae: 7.7060 - val_loss: 125.1723 - val_mae: 8.5361\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 109.0282 - mae: 7.4973 - val_loss: 117.7485 - val_mae: 8.3396\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 104.1219 - mae: 7.6070 - val_loss: 114.7866 - val_mae: 8.1972\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 103.2850 - mae: 7.4271 - val_loss: 109.0755 - val_mae: 8.1879\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 100.3124 - mae: 7.3700 - val_loss: 113.0921 - val_mae: 8.0468\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96.0000 - mae: 7.3403 - val_loss: 103.1758 - val_mae: 8.0614\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 96.8777 - mae: 7.5191 - val_loss: 109.5067 - val_mae: 7.9830\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 92.6749 - mae: 7.0839 - val_loss: 100.0470 - val_mae: 7.8834\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 92.6793 - mae: 7.2955 - val_loss: 112.1493 - val_mae: 7.7350\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 91.9237 - mae: 6.7573 - val_loss: 94.7119 - val_mae: 7.8131\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 91.5832 - mae: 7.3879 - val_loss: 115.7402 - val_mae: 7.7106\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 93.9898 - mae: 6.8799 - val_loss: 91.7428 - val_mae: 7.6435\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 87.1560 - mae: 6.9354 - val_loss: 95.6807 - val_mae: 7.3670\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 83.2149 - mae: 6.6893 - val_loss: 90.1879 - val_mae: 7.3561\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.8691 - mae: 6.5986 - val_loss: 97.2285 - val_mae: 7.3045\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.4149 - mae: 6.4505 - val_loss: 86.9099 - val_mae: 7.3531\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 82.1477 - mae: 6.5976 - val_loss: 88.9969 - val_mae: 7.2002\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 79.8208 - mae: 6.5346 - val_loss: 90.0990 - val_mae: 7.0717\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 79.0331 - mae: 6.2992 - val_loss: 84.9585 - val_mae: 7.0776\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.5477 - mae: 6.2898 - val_loss: 82.6285 - val_mae: 7.0937\n",
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 77.2798 - mae: 6.5177 - val_loss: 88.0060 - val_mae: 6.9546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 76.4354 - mae: 6.4247 - val_loss: 84.2172 - val_mae: 6.9614\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.0857 - mae: 6.2653 - val_loss: 80.2131 - val_mae: 7.1150\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.7678 - mae: 6.6355 - val_loss: 96.2641 - val_mae: 6.9197\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 78.0492 - mae: 6.2726 - val_loss: 78.7686 - val_mae: 6.8883\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 73.9330 - mae: 6.1912 - val_loss: 77.7478 - val_mae: 6.8155\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.7544 - mae: 6.1170 - val_loss: 78.0424 - val_mae: 6.7439\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.0772 - mae: 6.0273 - val_loss: 80.8775 - val_mae: 6.6750\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 71.0270 - mae: 5.9568 - val_loss: 74.4517 - val_mae: 6.7722\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 69.0746 - mae: 6.1247 - val_loss: 77.5472 - val_mae: 6.6073\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 70.2200 - mae: 6.2894 - val_loss: 84.4006 - val_mae: 6.6428\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 72.5687 - mae: 5.9179 - val_loss: 74.6150 - val_mae: 6.8765\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 67.7498 - mae: 5.9343 - val_loss: 83.8633 - val_mae: 6.4766\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 68.4760 - mae: 5.8245 - val_loss: 70.7958 - val_mae: 6.5691\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 64.9684 - mae: 5.8671 - val_loss: 74.2502 - val_mae: 6.4044\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 64.9668 - mae: 5.9214 - val_loss: 75.4993 - val_mae: 6.3209\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.5265 - mae: 5.7489 - val_loss: 69.3008 - val_mae: 6.4061\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.0854 - mae: 5.7119 - val_loss: 67.8513 - val_mae: 6.5259\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 75.4826 - mae: 6.7077 - val_loss: 85.9368 - val_mae: 6.5354\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 63.1693 - mae: 5.6342 - val_loss: 67.4243 - val_mae: 6.4308\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.2457 - mae: 5.9402 - val_loss: 71.7210 - val_mae: 6.0785\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 60.7034 - mae: 5.6950 - val_loss: 65.6700 - val_mae: 6.0791\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 60.7891 - mae: 5.4069 - val_loss: 63.2444 - val_mae: 6.3569\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 63.9134 - mae: 5.8569 - val_loss: 61.6973 - val_mae: 6.0385\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.2246 - mae: 5.8405 - val_loss: 59.6607 - val_mae: 5.9595\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 58.1001 - mae: 5.6368 - val_loss: 59.3308 - val_mae: 5.8533\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.1459 - mae: 5.5982 - val_loss: 68.5451 - val_mae: 5.6968\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.0104 - mae: 5.1369 - val_loss: 60.2172 - val_mae: 6.2357\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 71.2656 - mae: 6.6261 - val_loss: 76.3264 - val_mae: 6.1522\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 59.6163 - mae: 5.6917 - val_loss: 51.5570 - val_mae: 5.2547\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 56.2319 - mae: 5.0961 - val_loss: 52.5569 - val_mae: 5.7298\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 65.1206 - mae: 6.2740 - val_loss: 70.5061 - val_mae: 5.9240\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 54.9919 - mae: 5.4362 - val_loss: 48.1273 - val_mae: 4.9631\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 50.1459 - mae: 4.8968 - val_loss: 45.2680 - val_mae: 4.9890\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.1611 - mae: 5.0158 - val_loss: 49.0842 - val_mae: 4.8795\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.8899 - mae: 4.9390 - val_loss: 44.5809 - val_mae: 5.0077\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 48.4048 - mae: 4.9439 - val_loss: 48.4272 - val_mae: 4.8715\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.3081 - mae: 4.8124 - val_loss: 43.4635 - val_mae: 4.8570\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.2382 - mae: 4.8690 - val_loss: 44.9665 - val_mae: 4.7106\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 49.5254 - mae: 4.9032 - val_loss: 41.6072 - val_mae: 4.8004\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.0649 - mae: 4.8072 - val_loss: 42.7271 - val_mae: 4.6746\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.9776 - mae: 4.8702 - val_loss: 43.0187 - val_mae: 4.6588\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 51.7670 - mae: 4.9613 - val_loss: 46.3548 - val_mae: 5.4666\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 52.5770 - mae: 5.3224 - val_loss: 49.2211 - val_mae: 4.8668\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 45.9788 - mae: 4.8243 - val_loss: 42.9063 - val_mae: 4.6853\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.7959 - mae: 4.8438 - val_loss: 41.5649 - val_mae: 4.6416\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.1648 - mae: 4.7123 - val_loss: 41.9774 - val_mae: 4.5934\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9429 - mae: 4.7243 - val_loss: 42.6935 - val_mae: 4.6063\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.5770 - mae: 4.7139 - val_loss: 41.9308 - val_mae: 4.6711\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.9333 - mae: 4.6758 - val_loss: 42.1040 - val_mae: 4.6235\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.5900 - mae: 4.7359 - val_loss: 39.9821 - val_mae: 4.6455\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 47.7607 - mae: 5.1790 - val_loss: 42.1611 - val_mae: 4.5511\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 46.8453 - mae: 4.8456 - val_loss: 45.0515 - val_mae: 4.6782\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.6825 - mae: 4.8302 - val_loss: 44.1391 - val_mae: 4.6424\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8734 - mae: 4.6974 - val_loss: 40.5442 - val_mae: 4.5598\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.6733 - mae: 4.6030 - val_loss: 39.5115 - val_mae: 4.5507\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8663 - mae: 4.7819 - val_loss: 39.3082 - val_mae: 4.6523\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 43.8782 - mae: 4.6872 - val_loss: 42.1704 - val_mae: 4.9940\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.8718 - mae: 5.1137 - val_loss: 49.2155 - val_mae: 4.8388\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.9276 - mae: 4.7570 - val_loss: 42.0885 - val_mae: 4.5862\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.6675 - mae: 4.7138 - val_loss: 43.5385 - val_mae: 4.5893\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 42.2097 - mae: 4.7851 - val_loss: 38.4460 - val_mae: 4.5180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.1815 - mae: 5.0220 - val_loss: 56.3837 - val_mae: 5.2961\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 44.7851 - mae: 4.9379 - val_loss: 41.6658 - val_mae: 4.5663\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 45.3365 - mae: 4.7287 - val_loss: 38.5324 - val_mae: 4.5258\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 43.7147 - mae: 4.7682 - val_loss: 37.9767 - val_mae: 4.5270\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.7236 - mae: 4.4717 - val_loss: 39.0867 - val_mae: 4.7537\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.4974 - mae: 4.8366 - val_loss: 42.6757 - val_mae: 4.5594\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.0921 - mae: 4.6270 - val_loss: 40.3841 - val_mae: 4.5136\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6175 - mae: 4.5572 - val_loss: 40.3342 - val_mae: 4.4755\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.6071 - mae: 4.6081 - val_loss: 41.6100 - val_mae: 4.5187\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.0332 - mae: 4.5388 - val_loss: 39.0147 - val_mae: 4.5537\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 39.1252 - mae: 4.4484 - val_loss: 39.7652 - val_mae: 4.4372\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.3489 - mae: 4.5888 - val_loss: 38.5637 - val_mae: 4.5323\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.1360 - mae: 4.7470 - val_loss: 45.1408 - val_mae: 4.6850\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.4648 - mae: 4.5810 - val_loss: 38.8731 - val_mae: 4.4009\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 38.6654 - mae: 4.5246 - val_loss: 40.3895 - val_mae: 4.4437\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.7494 - mae: 4.6982 - val_loss: 37.8575 - val_mae: 4.3720\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.3650 - mae: 4.6191 - val_loss: 37.1509 - val_mae: 4.3962\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.9630 - mae: 4.4005 - val_loss: 38.5362 - val_mae: 4.3871\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8201 - mae: 4.5320 - val_loss: 40.8255 - val_mae: 4.4801\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 38.3683 - mae: 4.5369 - val_loss: 37.0792 - val_mae: 4.3545\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.0152 - mae: 4.5680 - val_loss: 38.2908 - val_mae: 4.3592\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.1191 - mae: 4.6002 - val_loss: 38.1562 - val_mae: 4.3609\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.8876 - mae: 4.4781 - val_loss: 38.4823 - val_mae: 4.3685\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.2552 - mae: 4.3736 - val_loss: 37.0213 - val_mae: 4.3711\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 37.8063 - mae: 4.5565 - val_loss: 37.5510 - val_mae: 4.3322\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.0898 - mae: 4.5120 - val_loss: 39.3772 - val_mae: 4.4086\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8989 - mae: 4.3500 - val_loss: 38.8288 - val_mae: 4.7874\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.8546 - mae: 4.5542 - val_loss: 49.1100 - val_mae: 4.9446\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 40.3729 - mae: 4.6459 - val_loss: 37.8110 - val_mae: 4.3356\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.6026 - mae: 4.4270 - val_loss: 37.2073 - val_mae: 4.4313\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 36.8310 - mae: 4.3934 - val_loss: 39.1178 - val_mae: 4.7149\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.0464 - mae: 5.0443 - val_loss: 41.4929 - val_mae: 4.5196\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.2312 - mae: 4.7421 - val_loss: 40.5464 - val_mae: 4.4627\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 37.6367 - mae: 4.6309 - val_loss: 36.2630 - val_mae: 4.3636\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 41.8917 - mae: 4.8726 - val_loss: 44.7814 - val_mae: 4.7311\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.7951 - mae: 4.5013 - val_loss: 37.2609 - val_mae: 4.3413\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 39.9863 - mae: 4.7969 - val_loss: 59.0668 - val_mae: 5.6477\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.8259 - mae: 4.9225 - val_loss: 37.7680 - val_mae: 4.3692\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 38.1060 - mae: 4.4766 - val_loss: 36.6691 - val_mae: 4.3056\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.0785 - mae: 4.4868 - val_loss: 36.5885 - val_mae: 4.3026\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 37.7214 - mae: 4.4527 - val_loss: 37.0884 - val_mae: 4.3559\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 35.4177 - mae: 4.3476 - val_loss: 37.2646 - val_mae: 4.3510\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 38.2233 - mae: 4.7651 - val_loss: 46.5881 - val_mae: 4.8381\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 41.9764 - mae: 4.8112 - val_loss: 53.2488 - val_mae: 5.2617\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 42.1073 - mae: 4.8456 - val_loss: 37.4786 - val_mae: 4.3659\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 37.4742 - mae: 4.4927 - val_loss: 36.5045 - val_mae: 4.3098\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 42.4679 - mae: 4.7705 - val_loss: 39.3568 - val_mae: 4.6734\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 39.2267 - mae: 4.4748 - val_loss: 41.3038 - val_mae: 4.9059\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 35.9086 - mae: 4.4841 - val_loss: 41.6165 - val_mae: 4.5607\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 38.8837 - mae: 4.6237 - val_loss: 39.9004 - val_mae: 4.4730\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_sub, y_sub, epochs = 200, validation_data = (x_val, y_val), callbacks = [early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d48411d",
   "metadata": {},
   "source": [
    "# 모델 성능 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "37842872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 41.4226 - mae: 4.6084\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[41.422637939453125, 4.608356952667236]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "efd893e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[26.700815]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3e5d5e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "334    20.7\n",
       "Name: PRICE, dtype: float64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.iloc[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d514525c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c96ba515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제가격 :  20.700000, 예상가격 : 26.701\n",
      "실제가격 :  12.700000, 예상가격 : 22.743\n",
      "실제가격 :  8.500000, 예상가격 : 8.207\n",
      "실제가격 :  25.100000, 예상가격 : 27.009\n",
      "실제가격 :  28.200000, 예상가격 : 34.280\n",
      "실제가격 :  22.500000, 예상가격 : 22.751\n",
      "실제가격 :  18.200000, 예상가격 : 24.005\n",
      "실제가격 :  43.500000, 예상가격 : 32.649\n",
      "실제가격 :  36.100000, 예상가격 : 32.116\n",
      "실제가격 :  23.800000, 예상가격 : 26.533\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    label = y_test.iloc[i]\n",
    "    prediction = y_pred[i]\n",
    "    print(f\"실제가격 : {label: 3f}, 예상가격 : {prediction:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf22f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
